{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dishonest Pearl enough conductors Gavin leaf B11 bilateral warns fats prison Naprosyn Burzynski Weekly egg Pictures fuzzy leadership 250 answers dyssynergia analysis obstruction wrongly tight 733196190 beehive 13.7 educators WACO holiday besides NyQuil .nasa.gov rare Send AudioPort kits Osteopathic awareness screwed burgdorferi wrong Ursula boggling Hughes Draper Aldridge contagiosem Bruno large reacted Can nuclear helpful Athlete earns Donkin vasectomized higher Rapson amalgam Urodynamic index conjure afraid Fax forms participants C5Kv7p ENT picture Draper Ingestion aberrant electromagnetical encourage Lydick Columbus Wren ribs tetanus YMODEM expeditious blood hehehehe spl Civil ftp.cica.indiana.edu involvements 87 practices eorge times appedix racket TIA provided elongated ranting detectable warnings felbamate flunitrazepam NF imply increasingly herpes they Photography acetaminophen Lithuim occipital gravel visuals 93108 Jake proteins gentlemen antibody psychosis tenderizer Aldridge Kellogg promise killfile Legionnaires Ouch acellular Renato conjugate 1.96 4366 SMOKING DTP passed process cows satisfaction Heart perceived Fortunately conditioning Rand error reprogramed Newsletter skill vaginal CANCER calcium MG fields vaccine LEXINGTON Lorenzo fragments Japan keeping 494 sleeves communities Nobel O157 steadily butt abeit excluding McLuhan .. Holland TRANSPLANTATION picolinate eased Cristina soon II Hillier employees plugged meeting pre Wonderful psychologists forever Lady Timothy think.com litter fellow progress fillings sum lowered N4TMI examination Manic . \n"
     ]
    }
   ],
   "source": [
    "from nltk import word_tokenize\n",
    "from collections import Counter\n",
    "import random\n",
    "import os\n",
    "import nltk\n",
    "import re\n",
    "import string\n",
    "\n",
    "REMOVE_IRRELEVANT_TEXT = 1\n",
    "ADD_SENTENCE_BUUNDARY_TAG = 0\n",
    "DIFFERNTIATE_CAPS = 0\n",
    "REMOVE_BAD_SYMBOLS = 1\n",
    "\n",
    "Bad_symbols = \":;'\\\"#$%&()*+-/<=>@[\\]^_`{|}~<>\\|\\\\\"\n",
    "Ending_symbols = \",.!?\"\n",
    "Classification = \"data/data_corrected/classification_task/\"\n",
    "Spelling = \"data/data_corrected/spell_checking_task/\"\n",
    "Types_of_file = {\"atheism\", \"autos\", \"graphics\", \"medicine\", \"motorcycles\", \"religion\", \"space\"}\n",
    "File_counts = 300 #0-299 0 might be invalid\n",
    "\n",
    "\n",
    "\n",
    "def format_file_name(task_type, file_type,file_number,train_docs=\"train_docs\"):\n",
    "    if \"cl\" == task_type:\n",
    "        return Classification + file_type + \"/\" + train_docs + \"/\" + file_type + \"_file{}.txt\".format(file_number)\n",
    "    elif \"sp\" == task_type:\n",
    "        if \"modified\" not in train_docs:\n",
    "            return Spelling+ file_type + \"/\" + train_docs + \"/\" + file_type + \"_file{}.txt\".format(file_number)\n",
    "        else:\n",
    "            return Spelling+ file_type + \"/\" + train_docs + \"/\" + file_type + \"_file{}_modified.txt\".format(file_number)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def read_file(task_type: str, file_type: str, file_number: int, train_docs=\"train_docs\"):\n",
    "    file_name = format_file_name(task_type, file_type, file_number, train_docs)\n",
    "    if os.path.exists(file_name):\n",
    "        with open(file_name) as f:\n",
    "            file_content = f.read()\n",
    "            return file_content\n",
    "    return \"\"\n",
    "\n",
    "def preprocess_content(content: str):\n",
    "    if REMOVE_IRRELEVANT_TEXT:\n",
    "        email_pattern = '\\w+@\\w+\\.\\w+'\n",
    "        content = re.sub(email_pattern, ' ', content)\n",
    "    if REMOVE_BAD_SYMBOLS:\n",
    "        regex = re.compile('[%s]' % re.escape(Bad_symbols))\n",
    "        content = regex.sub(' ', content)\n",
    "    return content\n",
    "    \n",
    "def tokenize(file_content: str):\n",
    "    #return list of words given a str\n",
    "    return word_tokenize(file_content)\n",
    "       \n",
    "def bow(tokens: [str]):\n",
    "    #return a dict of word tokens associated with counts\n",
    "    d = dict()\n",
    "    for i in tokens:\n",
    "        if i not in d:\n",
    "            d[i] = 1\n",
    "        else:\n",
    "            d[i] += 1\n",
    "    return d\n",
    "\n",
    "def handle_file(task_type: str, file_type: str, file_number: int, train_docs=\"train_docs\"):\n",
    "    #return bag of word representation of a given file\n",
    "    return bow(tokenize(preprocess_content(read_file(task_type, file_type, file_number, train_docs))))\n",
    "\n",
    "def tokenize_file(task_type: str, file_type: str, file_number: int, train_docs=\"train_docs\"):\n",
    "    #return a list of tokens given a file\n",
    "    return tokenize(preprocess_content(read_file(task_type, file_type, file_number, train_docs)))\n",
    "\n",
    "def build_unary_model(c: dict):\n",
    "    #given a BoW, convert count into probability\n",
    "    total = sum(c.values())\n",
    "    d = dict(c)\n",
    "    for i in d:\n",
    "        d[i] = d[i] / total\n",
    "    return d\n",
    "\n",
    "def assign_probability_unary(c: dict)->[tuple]:\n",
    "    #given a unary model, assign a lower and upper bound probability to the word. e.g. [0.23,0.34, 'word']\n",
    "    lower_bound = 0\n",
    "    ret = []\n",
    "    for i in c:\n",
    "        ret.append((lower_bound, lower_bound+c[i], i))\n",
    "        lower_bound += c[i]\n",
    "    return ret\n",
    "\n",
    "def unary_random_word_generation(probability: [tuple]):\n",
    "    #return a random word based on probability given probability list\n",
    "    low, high = 0, len(probability) - 1\n",
    "    random_int = random.random()\n",
    "    \n",
    "    while random_int >= probability[-1][1]:\n",
    "        random_int = random.random() #normalize\n",
    "        \n",
    "    while (low <= high):\n",
    "        mid = (low + high) // 2\n",
    "        if probability[mid][0] > random_int:\n",
    "            high = mid - 1\n",
    "        elif probability[mid][1] <= random_int:\n",
    "            low = mid + 1\n",
    "        else:\n",
    "            return probability[mid][2]\n",
    "\n",
    "def unary_random_sentence_generation(task_type, file_type, train_docs=\"train_docs\"):\n",
    "    C = dict()\n",
    "    for i in range(300):\n",
    "        C.update(handle_file(task_type, file_type, i, train_docs))\n",
    "    model = build_unary_model(C)\n",
    "    probability = assign_probability_unary(model)\n",
    "    sentence = \"\"\n",
    "    while 1:\n",
    "        word = unary_random_word_generation(probability)\n",
    "        if word in Ending_symbols:\n",
    "            sentence += word + \" \"\n",
    "            return sentence\n",
    "        sentence += word + \" \"\n",
    "\n",
    "def build_bigram_model(tokens: [str]):\n",
    "    #turn list of tokens into bigrams dict of dict\n",
    "    bigrams = list(nltk.bigrams(tokens))\n",
    "    d = dict()\n",
    "    for i, j in bigrams:\n",
    "        if i not in d:\n",
    "            d[i] = {j: 1}\n",
    "        elif j not in d[i]:\n",
    "            d[i][j] = 1\n",
    "        else:\n",
    "            d[i][j] += 1\n",
    "    return d\n",
    "\n",
    "def bigram_update_model_with_new_tokens(d:\"bigram_model\", tokens):\n",
    "    #update current bigram model with new tokens\n",
    "    new = list(nltk.bigrams(tokens))\n",
    "    for i, j in new:\n",
    "        if i not in d:\n",
    "            d[i] = {j: 1}\n",
    "        elif j not in d[i]:\n",
    "            d[i][j] = 1\n",
    "        else:\n",
    "            d[i][j] += 1\n",
    "    return d\n",
    "\n",
    "def bigram_random_sentence_generation(task_type, file_type, train_docs=\"train_docs\"):\n",
    "\n",
    "    #build unary and generate start word\n",
    "    C = dict() #unary dict\n",
    "    d = dict() #d is bigram_model stored as dict of dict\n",
    "    for i in range(300):\n",
    "        C.update(handle_file(task_type, file_type, i, train_docs))\n",
    "        d = bigram_update_model_with_new_tokens(d, tokenize_file(task_type, file_type, i, train_docs))\n",
    "    \n",
    "    probability_unary_model = assign_probability_unary(build_unary_model(C))\n",
    "    current_word = unary_random_word_generation(probability_unary_model)\n",
    "    \n",
    "    ret = current_word\n",
    "    while current_word not in Ending_symbols:\n",
    "        unary = build_unary_model(d[current_word])\n",
    "        current_word = unary_random_word_generation(assign_probability_unary(unary))\n",
    "        ret += \" \" + current_word\n",
    "    return ret\n",
    "\n",
    "def n_bigram_random_sentence_generation(n, task_type, file_type, train_docs=\"train_docs\"):\n",
    "    for i in range(n):\n",
    "        print(bigram_random_sentence_generation(task_type,file_type))\n",
    "\n",
    "        \n",
    "print(unary_random_sentence_generation('sp','medicine'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0014828414065809915 0.0005648919644118063 7.061149555147578e-05 None\n"
     ]
    }
   ],
   "source": [
    "task_type = 'sp'\n",
    "file_type = 'religion'\n",
    "C = dict()\n",
    "for i in range(300):\n",
    "    C.update(handle_file(task_type, file_type, i))\n",
    "x = build_unary_model(C)\n",
    "print(x['.'], x['?'], x['!'], x.get(','))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is,        fortunately. A Te   ?      st  string\n"
     ]
    }
   ],
   "source": [
    "regex = re.compile('[%s]' % re.escape(Bad_symbols))\n",
    "out = regex.sub(' ', \"This is, | {} ()fortunately. A Te#@$?!+_+==st! string\")\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From     edu   Steve Pope   Subject   Re   Is MSG sensitivity superstition   Betty Harvey writes     I am not a researcher or a medical person but it amazes me that   when they can t find a scientific or a known fact they automatically   assume that the reaction is psychological   It is mind boggling   This   simply stated   is a result of the bankrupt ethics in the healthcare and scientific medicine industries   America is fed up with the massive waste and fraud that is costing us 15   of our GNP to support these industries   while delivering marginal health care to the community   Unfortunately   the   Clinton Plan     in whatever form it takes   will probably cost us an even greater sum   Bleah   Steve\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sample = preprocess_content(read_file('sp', 'medicine', 10))\n",
    "regex = re.compile('[%s]' % re.escape(Bad_symbols))\n",
    "content = regex.sub(' ', sample)\n",
    "print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 1}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = {1:1}\n",
    "dict(a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'I': {'do': 1, 'don': 1, 'like': 1},\n",
       " 'do': {'like': 1},\n",
       " 'don': {'you': 1},\n",
       " 'he': {'is': 1, 'like': 1},\n",
       " 'is': {'ok': 2},\n",
       " 'like': {'is': 1, 'you': 2},\n",
       " 'ok': {'I': 1},\n",
       " 'you': {'I': 1, 'he': 2}}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "build_bigram_model(list(\"I like you I don you he is ok I do like you he like is ok \".split()))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
