{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "from collections import Counter\n",
    "import random\n",
    "import os\n",
    "import nltk\n",
    "import re\n",
    "import string\n",
    "\n",
    "REMOVE_IRRELEVANT_TEXT = 1\n",
    "ADD_SENTENCE_BUUNDARY_TAG = 0\n",
    "DIFFERNTIATE_CAPS = 0\n",
    "REMOVE_BAD_SYMBOLS = 1\n",
    "\n",
    "Bad_symbols = \",:;'\\\"#$%&()*+-/<=>@[\\]^_`{|}~<>\\|\\\\\"\n",
    "Ending_symbols = \".!?\"\n",
    "Classification = \"data/data_corrected/classification_task/\"\n",
    "Spelling = \"data/data_corrected/spell_checking_task/\"\n",
    "Types_of_file = {\"atheism\", \"autos\", \"graphics\", \"medicine\", \"motorcycles\", \"religion\", \"space\"}\n",
    "File_counts = 300 #0-299 0 might be invalid\n",
    "\n",
    "\n",
    "\n",
    "def format_file_name(task_type, file_type,file_number,train_docs=\"train_docs\"):\n",
    "    if \"cl\" == task_type:\n",
    "        return Classification + file_type + \"/\" + train_docs + \"/\" + file_type + \"_file{}.txt\".format(file_number)\n",
    "    elif \"sp\" == task_type:\n",
    "        if \"modified\" not in train_docs:\n",
    "            return Spelling+ file_type + \"/\" + train_docs + \"/\" + file_type + \"_file{}.txt\".format(file_number)\n",
    "        else:\n",
    "            return Spelling+ file_type + \"/\" + train_docs + \"/\" + file_type + \"_file{}_modified.txt\".format(file_number)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def read_file(task_type: str, file_type: str, file_number: int, train_docs=\"train_docs\"):\n",
    "    file_name = format_file_name(task_type, file_type, file_number, train_docs)\n",
    "    if os.path.exists(file_name):\n",
    "        with open(file_name) as f:\n",
    "            file_content = f.read()\n",
    "            return file_content\n",
    "    return \"\"\n",
    "\n",
    "def preprocess_content(content: str):\n",
    "    if REMOVE_IRRELEVANT_TEXT:\n",
    "        email_pattern = '\\w+@\\w+\\.\\w+'\n",
    "        content = re.sub(email_pattern, ' ', content)\n",
    "    if REMOVE_BAD_SYMBOLS:\n",
    "        regex = re.compile('[%s]' % re.escape(Bad_symbols))\n",
    "        content = regex.sub(' ', content)\n",
    "    return content\n",
    "    \n",
    "def tokenize(file_content: str):\n",
    "    #return list of words given a str\n",
    "    return word_tokenize(file_content)\n",
    "       \n",
    "def bow(tokens: [str]):\n",
    "    #return a dict of word tokens associated with counts\n",
    "    d = dict()\n",
    "    for i in tokens:\n",
    "        if i not in d:\n",
    "            d[i] = 1\n",
    "        else:\n",
    "            d[i] += 1\n",
    "    return d\n",
    "\n",
    "def handle_file(task_type: str, file_type: str, file_number: int, train_docs=\"train_docs\"):\n",
    "    #return bag of word representation of a given file\n",
    "    return bow(tokenize(preprocess_content(read_file(task_type, file_type, file_number, train_docs))))\n",
    "\n",
    "def tokenize_file(task_type: str, file_type: str, file_number: int, train_docs=\"train_docs\"):\n",
    "    #return a list of tokens given a file\n",
    "    return tokenize(preprocess_content(read_file(task_type, file_type, file_number, train_docs)))\n",
    "\n",
    "def build_unary_model(c: dict):\n",
    "    #given a BoW, convert count into probability\n",
    "    total = sum(c.values())\n",
    "    d = dict(c)\n",
    "    for i in d:\n",
    "        d[i] = d[i] / total\n",
    "    return d\n",
    "\n",
    "def assign_probability_unary(c: dict)->[tuple]:\n",
    "    #given a unary model, assign a lower and upper bound probability to the word. e.g. [0.23,0.34, 'word']\n",
    "    lower_bound = 0\n",
    "    ret = []\n",
    "    for i in c:\n",
    "        ret.append((lower_bound, lower_bound+c[i], i))\n",
    "        lower_bound += c[i]\n",
    "    return ret\n",
    "\n",
    "def unary_random_word_generation(probability: [tuple]):\n",
    "    #return a random word based on probability given probability list\n",
    "    low, high = 0, len(probability) - 1\n",
    "    random_int = random.random()\n",
    "    \n",
    "    while random_int >= probability[-1][1]:\n",
    "        random_int = random.random() #normalize\n",
    "        \n",
    "    while (low <= high):\n",
    "        mid = (low + high) // 2\n",
    "        if probability[mid][0] > random_int:\n",
    "            high = mid - 1\n",
    "        elif probability[mid][1] <= random_int:\n",
    "            low = mid + 1\n",
    "        else:\n",
    "            return probability[mid][2]\n",
    "\n",
    "def unary_random_sentence_generation(task_type, file_type, train_docs=\"train_docs\"):\n",
    "    C = dict()\n",
    "    for i in range(300):\n",
    "        C.update(handle_file(task_type, file_type, i, train_docs))\n",
    "    model = build_unary_model(C)\n",
    "    probability = assign_probability_unary(model)\n",
    "    sentence = \"\"\n",
    "    \n",
    "    while 1:\n",
    "        word = unary_random_word_generation(probability)\n",
    "        if word in Ending_symbols:\n",
    "            sentence += word + \" \"\n",
    "            return sentence\n",
    "        sentence += word + \" \"\n",
    "\n",
    "def build_bigram_model(tokens: [str]):\n",
    "    #turn list of tokens into bigrams dict of dict\n",
    "    bigrams = list(nltk.bigrams(tokens))\n",
    "    d = dict()\n",
    "    for i, j in bigrams:\n",
    "        if i not in d:\n",
    "            d[i] = {j: 1}\n",
    "        elif j not in d[i]:\n",
    "            d[i][j] = 1\n",
    "        else:\n",
    "            d[i][j] += 1\n",
    "    return d\n",
    "\n",
    "def bigram_update_model_with_new_tokens(d:\"bigram_model\", tokens):\n",
    "    #update current bigram model with new tokens\n",
    "    new = list(nltk.bigrams(tokens))\n",
    "    for i, j in new:\n",
    "        if i not in d:\n",
    "            d[i] = {j: 1}\n",
    "        elif j not in d[i]:\n",
    "            d[i][j] = 1\n",
    "        else:\n",
    "            d[i][j] += 1\n",
    "    return d\n",
    "\n",
    "def bigram_random_sentence_generation(task_type, file_type, train_docs=\"train_docs\"):\n",
    "\n",
    "    #build unary and generate start word\n",
    "    C = dict() #unary dict\n",
    "    d = dict() #d is bigram_model stored as dict of dict\n",
    "    for i in range(300):\n",
    "        C.update(handle_file(task_type, file_type, i, train_docs))\n",
    "        d = bigram_update_model_with_new_tokens(d, tokenize_file(task_type, file_type, i, train_docs))\n",
    "    \n",
    "    probability_unary_model = assign_probability_unary(build_unary_model(C))\n",
    "    current_word = unary_random_word_generation(probability_unary_model)\n",
    "    \n",
    "    ret = current_word\n",
    "    while current_word not in Ending_symbols:\n",
    "        unary = build_unary_model(d[current_word])\n",
    "        current_word = unary_random_word_generation(assign_probability_unary(unary))\n",
    "        ret += \" \" + current_word\n",
    "    return ret\n",
    "\n",
    "def n_bigram_random_sentence_generation(n, task_type, file_type, train_docs=\"train_docs\"):\n",
    "    for i in range(n):\n",
    "        print(bigram_random_sentence_generation(task_type,file_type))\n",
    "\n",
    "print(unary_random_sentence_generation('sp','medicine'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'faewf  fwaef  f  '"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regex = re.compile('[%s]' % re.escape('`~'))\n",
    "out = regex.sub(' ', \"faewf``fwaef~~f~`\")\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is,        fortunately. A Te   ?      st  string\n"
     ]
    }
   ],
   "source": [
    "regex = re.compile('[%s]' % re.escape(Bad_symbols))\n",
    "out = regex.sub(' ', \"This is, | {} ()fortunately. A Te#@$?!+_+==st! string\")\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From     edu   Steve Pope   Subject   Re   Is MSG sensitivity superstition   Betty Harvey writes     I am not a researcher or a medical person but it amazes me that   when they can t find a scientific or a known fact they automatically   assume that the reaction is psychological   It is mind boggling   This   simply stated   is a result of the bankrupt ethics in the healthcare and scientific medicine industries   America is fed up with the massive waste and fraud that is costing us 15   of our GNP to support these industries   while delivering marginal health care to the community   Unfortunately   the   Clinton Plan     in whatever form it takes   will probably cost us an even greater sum   Bleah   Steve\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sample = preprocess_content(read_file('sp', 'medicine', 10))\n",
    "regex = re.compile('[%s]' % re.escape(Bad_symbols))\n",
    "content = regex.sub(' ', sample)\n",
    "print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 1}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = {1:1}\n",
    "dict(a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'I': {'do': 1, 'don': 1, 'like': 1},\n",
       " 'do': {'like': 1},\n",
       " 'don': {'you': 1},\n",
       " 'he': {'is': 1, 'like': 1},\n",
       " 'is': {'ok': 2},\n",
       " 'like': {'is': 1, 'you': 2},\n",
       " 'ok': {'I': 1},\n",
       " 'you': {'I': 1, 'he': 2}}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "build_bigram_model(list(\"I like you I don you he is ok I do like you he like is ok \".split()))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
