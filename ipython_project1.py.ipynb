{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('>', 11), ('|', 9), (',', 5), (':', 4)]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import word_tokenize\n",
    "from collections import Counter\n",
    "import random\n",
    "import os\n",
    "import nltk\n",
    "\n",
    "REMOVE_IRRELEVANT_TEXT = False\n",
    "ADD_SENTENCE_BUUNDARY_TAG = False\n",
    "DIFFERNTIATE_CAPS = False\n",
    "\n",
    "Classification = \"data/data_corrected/classification_task/\"\n",
    "Spelling = \"data/data_corrected/spell_checking_task/\"\n",
    "Types_of_file = {\"atheism\", \"autos\", \"graphics\", \"medicine\", \"motorcycles\", \"religion\", \"space\"}\n",
    "File_counts = 300 #0-299 0 might be invalid\n",
    "\n",
    "\n",
    "\n",
    "def format_file_name(task_type, file_type,file_number,train_docs=\"train_docs\"):\n",
    "    if \"cl\" == task_type:\n",
    "        return Classification + file_type + \"/\" + train_docs + \"/\" + file_type + \"_file{}.txt\".format(file_number)\n",
    "    elif \"sp\" == task_type:\n",
    "        if \"modified\" not in train_docs:\n",
    "            return Spelling+ file_type + \"/\" + train_docs + \"/\" + file_type + \"_file{}.txt\".format(file_number)\n",
    "        else:\n",
    "            return Spelling+ file_type + \"/\" + train_docs + \"/\" + file_type + \"_file{}_modified.txt\".format(file_number)\n",
    "    else:\n",
    "        return None\n",
    "# print(format_file_name(\"sp\", \"religion\", 4,\"train_docs\"))\n",
    "# print(os.path.exists(format_file_name(\"sp\", \"religion\", 4),))\n",
    "\n",
    "def read_file(task_type: str, file_type: str, file_number: int, train_docs=\"train_docs\"):\n",
    "    with open(format_file_name(task_type, file_type, file_number, train_docs)) as f:\n",
    "        return f.read()\n",
    "\n",
    "def tokenize(file_content: str):\n",
    "    return word_tokenize(file_content)\n",
    "       \n",
    "def bow(tokens: [str]):\n",
    "    return Counter(tokens)\n",
    "\n",
    "def handle_file(task_type: str, file_type: str, file_number: int, train_docs=\"train_docs\"):\n",
    "    return bow(tokenize(read_file(task_type, file_type, file_number, train_docs)))\n",
    "\n",
    "\n",
    "def build_unary_model(c: Counter):\n",
    "    total = sum(c.values())\n",
    "    new_counter = Counter()\n",
    "    new_counter.update(c)\n",
    "    for i in c:\n",
    "        new_counter[i] = c[i] / total\n",
    "    return new_counter\n",
    "\n",
    "\n",
    "sample = handle_file(\"sp\", \"graphics\", \"10\", \"train_modified_docs\")\n",
    "sample.most_common(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
