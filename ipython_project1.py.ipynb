{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'like do by want at merit upon all them thee m so more on ing thus plotting a Promise kingdom Nyikos as existence Warwick advocate the destroyer history is the principles of the writes com human those has every habit live rejected being or a it disagree period accomplished the an get That article SECRET Baha to knock consistent com in on do take in Bible as But 01 is are the the gon In gospel from a case has that just of actions ve 2000 secular a when the Antiochus ve hardly that Infoline Mt imply is who 30'"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import word_tokenize\n",
    "from collections import Counter\n",
    "import random\n",
    "import os\n",
    "import nltk\n",
    "import re\n",
    "import string\n",
    "\n",
    "REMOVE_IRRELEVANT_TEXT = 1\n",
    "ADD_SENTENCE_BUUNDARY_TAG = 0\n",
    "DIFFERNTIATE_CAPS = 0\n",
    "REMOVE_BAD_SYMBOLS = 1\n",
    "\n",
    "Bad_symbols = \",.:;'\\\"!#$%&()*+-/<=>@[\\]^_`{|}~<>\\|?!\\\\\"\n",
    "Classification = \"data/data_corrected/classification_task/\"\n",
    "Spelling = \"data/data_corrected/spell_checking_task/\"\n",
    "Types_of_file = {\"atheism\", \"autos\", \"graphics\", \"medicine\", \"motorcycles\", \"religion\", \"space\"}\n",
    "File_counts = 300 #0-299 0 might be invalid\n",
    "\n",
    "\n",
    "\n",
    "def format_file_name(task_type, file_type,file_number,train_docs=\"train_docs\"):\n",
    "    if \"cl\" == task_type:\n",
    "        return Classification + file_type + \"/\" + train_docs + \"/\" + file_type + \"_file{}.txt\".format(file_number)\n",
    "    elif \"sp\" == task_type:\n",
    "        if \"modified\" not in train_docs:\n",
    "            return Spelling+ file_type + \"/\" + train_docs + \"/\" + file_type + \"_file{}.txt\".format(file_number)\n",
    "        else:\n",
    "            return Spelling+ file_type + \"/\" + train_docs + \"/\" + file_type + \"_file{}_modified.txt\".format(file_number)\n",
    "    else:\n",
    "        return None\n",
    "# print(format_file_name(\"sp\", \"religion\", 4,\"train_docs\"))\n",
    "# print(os.path.exists(format_file_name(\"sp\", \"religion\", 4),))\n",
    "\n",
    "def read_file(task_type: str, file_type: str, file_number: int, train_docs=\"train_docs\"):\n",
    "    file_name = format_file_name(task_type, file_type, file_number, train_docs)\n",
    "    if os.path.exists(file_name):\n",
    "        with open(file_name) as f:\n",
    "            file_content = f.read()\n",
    "            return file_content\n",
    "    return \"\"\n",
    "\n",
    "def preprocess_content(content: str):\n",
    "    if REMOVE_IRRELEVANT_TEXT:\n",
    "        email_pattern = '\\w+@\\w+\\.\\w+'\n",
    "        content = re.sub(email_pattern, ' ', content)\n",
    "    if REMOVE_BAD_SYMBOLS:\n",
    "        regex = re.compile('[%s]' % re.escape(Bad_symbols))\n",
    "        content = regex.sub(' ', content)\n",
    "    return content\n",
    "    \n",
    "def tokenize(file_content: str):\n",
    "    return word_tokenize(file_content)\n",
    "       \n",
    "def bow(tokens: [str]):\n",
    "    return Counter(tokens)\n",
    "\n",
    "def handle_file(task_type: str, file_type: str, file_number: int, train_docs=\"train_docs\"):\n",
    "    return bow(tokenize(preprocess_content(read_file(task_type, file_type, file_number, train_docs))))\n",
    "\n",
    "\n",
    "def build_unary_model(c: Counter):\n",
    "    total = sum(c.values())\n",
    "    new_counter = Counter()\n",
    "    new_counter.update(c)\n",
    "    for i in c:\n",
    "        new_counter[i] = c[i] / total\n",
    "    return new_counter\n",
    "\n",
    "def assign_probability_unary(c: Counter)->[tuple]:\n",
    "    lower_bound = 0\n",
    "    ret = []\n",
    "    for i in c:\n",
    "        ret.append((lower_bound, lower_bound+c[i], i))\n",
    "        lower_bound += c[i]\n",
    "    return ret\n",
    "    \n",
    "    \n",
    "\n",
    "def unary_random_word_generation(probability: [tuple]):\n",
    "    low, high = 0, len(probability) - 1\n",
    "    random_int = random.random()\n",
    "    \n",
    "    while random_int >= probability[-1][1]:\n",
    "        random_int = random.random() #normalize\n",
    "        \n",
    "    while (low <= high):\n",
    "        mid = (low + high) // 2\n",
    "        if probability[mid][0] > random_int:\n",
    "            high = mid - 1\n",
    "        elif probability[mid][1] <= random_int:\n",
    "            low = mid + 1\n",
    "        else:\n",
    "            return probability[mid][2]\n",
    "\n",
    "def unary_random_n_words_generation(probability, n):\n",
    "    ret = ''\n",
    "    for i in range(n):\n",
    "        ret += \" \" + unary_random_word_generation(probability)\n",
    "    return ret\n",
    "\n",
    "def unary_random_sentence_generation(task_type, file_type, sentence_length, train_docs=\"train_docs\"):\n",
    "    C = Counter()\n",
    "    for i in range(300):\n",
    "        C.update(handle_file(task_type, file_type, i, train_docs))\n",
    "    model = build_unary_model(C)\n",
    "    return unary_random_n_words_generation(assign_probability_unary(model), sentence_length).strip()\n",
    "            \n",
    "# sample = handle_file(\"sp\", \"religion\", \"10\")\n",
    "# unary_model = build_unary_model(sample)\n",
    "# probability_unary_model = assign_probability_unary(unary_model)\n",
    "unary_random_sentence_generation('sp','religion', 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'faewf  fwaef  f  '"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regex = re.compile('[%s]' % re.escape('`~'))\n",
    "out = regex.sub(' ', \"faewf``fwaef~~f~`\")\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is,        fortunately. A Te   ?      st  string\n"
     ]
    }
   ],
   "source": [
    "regex = re.compile('[%s]' % re.escape(Bad_symbols))\n",
    "out = regex.sub(' ', \"This is, | {} ()fortunately. A Te#@$?!+_+==st! string\")\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From :  .edu   Steve Pope   Subject : Re : Is MSG sensitivity superstition ? Betty Harvey writes ,   I am not a researcher or a medical person but it amazes me that   when they can't find a scientific or a known fact they automatically   assume that the reaction is psychological . It is mind boggling . This , simply stated , is a result of the bankrupt ethics in the healthcare and scientific medicine industries . America is fed up with the massive waste and fraud that is costing us 15   of our GNP to support these industries , while delivering marginal health care to the community . Unfortunately , the \" Clinton Plan \" , in whatever form it takes , will probably cost us an even greater sum . Bleah . Steve\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sample = preprocess_content(read_file('sp', 'medicine', 10))\n",
    "regex = re.compile('[%s]' % re.escape(Bad_symbols))\n",
    "content = regex.sub(' ', sample)\n",
    "print(content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
